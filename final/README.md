# Final Project：Toy Model — 多模態情緒理解與策略選擇

本專案的核心問題是：未來的人工智慧是否能「理解人類的動機、情緒與價值」，並且根據使用者的潛在心理狀態主動做出合適協作？  
這是一個非常困難的目標，因此我設計了一個 **Toy Model（簡化版模型）**，用於模擬未來能力的最小可行雛形。本模型包含兩大部分：

- 多模態情緒分類（Perception）  
- 策略選擇強化學習（Action / RL）

本模型的目的不是完美複製真實世界的對話 AI，而是建立一個能「測試觀念、可運行、可評估」的架構。

---

## 1. Toy Model 的目的

Toy Model 要做的事情，是把未來「理解人 → 主動協作」的複雜行為，拆解成目前可實作的最小雛形：

1. 讓 AI 接收簡化的多模態資料  
2. 推測使用者的情緒狀態  
3. 根據情緒選擇回應策略  
4. 使用強化學習優化策略品質  

這個流程建立了未來 AI 會需要的兩大能力：**理解（Perception）** 與 **行動（Decision-Making）**。

---

## 2. Toy Model 的輸入與輸出

### 輸入：20 維多模態向量

Toy Model 的資料由三種模態組成（以隨機向量模擬）：

- 語音特徵：5 維  
- 臉部特徵：5 維  
- 文本 embedding：10 維  

組合成：

x ∈ R^20
